
\section{Empirical Analysis}
In this section, we present the experimental evaluation for our \textit{k}-center algorithm. We implemented the algorithm described in the previous sections using cover trees \cite{beygelzimer2006cover, kollar2006fast}, which is a fast variant of navigating nets. The cover tree maintains the same invariants as navigating nets, except that for a point at a certain level in the hierarchy, we store \textit{exactly one} nearby point one level up, instead of a set of points that are nearby. Beygelzimer et al. \cite{beygelzimer2006cover} show that all running time guarantees can be maintained for metric spaces with bounded expansion constant. This in turn implies that using a collection of cover trees yields a $(2 + \varepsilon)$-approximation for the \textit{k}-center clustering problem. The expansion constant of $M$ is defined as the smallest value $c \geq 2$ such that $\left| B(p, 2r) \right| \leq c \left| B(p, r) \right|$ for all $p \in M$ and $r > 0$. Our algorithm maintains $O(\varepsilon^{-1} \ln \varepsilon^{-1})$ cover trees. To obtain the current centers of a cover tree, we traverse the tree top-down and add all distinct points until we have $k$ points. Due to the \textit{nesting property} of the cover tree, i.e., every point which appears in some level $i$ appears in every lower level $j < i$ in the tree \cite{beygelzimer2006cover}, we are guaranteed to add all nodes of the desired level $Y^p_r$ described in Section 3.2. From now on we call our algorithm $A_{\text{Cov}}$. 

We compare our algorithm against the algorithm of Chan et al. \cite{hubert2018dynamic} which is the state-of-the-art approach for the fully dynamic \textit{k}-center problem in practice.
